{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1dd8f766",
   "metadata": {},
   "source": [
    "# Hw-1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e44290",
   "metadata": {},
   "source": [
    "We are interested in studying whether and how changes in environmental factors predict\n",
    "future temperatures. To do this, first read the dataset climate change.csv into Python\n",
    "(do not forget to place this file in the same folder on your computer as your Python notebook).\n",
    "Then split the data into a training set, consisting of all the observations up to and including\n",
    "2002, and a test set consisting of the remaining years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e77ea68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4bb090a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('C:\\\\Users\\\\mmali\\\\OneDrive\\\\Desktop\\\\Mini 3\\\\46886 - Machine Learning Fundamentals\\\\HW-1\\\\climate_change.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "16ca034f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df[df['Year'] <= 2002]\n",
    "df_test = df[df['Year'] > 2002]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd8a79ec",
   "metadata": {},
   "source": [
    "(a) Build a linear regression model to predict the dependent variable Temp, using CO2,\n",
    "CH4, N2O, CFC-11, CFC-12, Aerosols, TSI and MEI as features (Year and Month\n",
    "should NOT be used as features in the model). As always, use only the training set to\n",
    "train your model. What are the in-sample and out-of-sample R2\n",
    ", MSE, and MAE?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e947f99e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a \"blank\" linear regression model\n",
    "LR_a = LinearRegression()\n",
    "\n",
    "# Using the \"fit\" function, which takes two arguments:\n",
    "# (1) A DataFrame consisting of the features (X),\n",
    "# and (2) a single column consisting of the dependent variable (y)\n",
    "features = ['CO2', 'CH4', 'N2O', 'CFC-11', 'CFC-12', 'Aerosols', 'TSI', 'MEI']\n",
    "X_train = df_train[features]\n",
    "y_train = df_train['Temp']\n",
    "LR_a.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4a9527db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In-sample R2 is:  0.6920595959984911\n",
      "In-sample MSE is:  0.008731426409910696\n",
      "In-sample MAE is:  0.07260918612938558\n",
      "Out-of-sample R2 is:  -0.5413255834033228\n",
      "Out-of-sample MSE is:  0.012206974835145303\n",
      "Out-of-sample MAE is:  0.09312747891279667\n"
     ]
    }
   ],
   "source": [
    "X_test = df_test[features]\n",
    "y_test = df_test['Temp']\n",
    "\n",
    "# in-sample and out-of-sample R2 , MSE, and MAE\n",
    "y_train_pred = LR_a.predict(X_train) #for in-sample\n",
    "y_test_pred = LR_a.predict(X_test) #for out-of-sample\n",
    "\n",
    "print(\"In-sample R2 is: \", r2_score(y_train,y_train_pred))\n",
    "print(\"In-sample MSE is: \",mean_squared_error(y_train,y_train_pred))\n",
    "print(\"In-sample MAE is: \",mean_absolute_error(y_train,y_train_pred))\n",
    "\n",
    "print(\"Out-of-sample R2 is: \", r2_score(y_test,y_test_pred))\n",
    "print(\"Out-of-sample MSE is: \",mean_squared_error(y_test,y_test_pred))\n",
    "print(\"Out-of-sample MAE is: \",mean_absolute_error(y_test,y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87314f8f",
   "metadata": {},
   "source": [
    "(b) Build another linear regression model, this time with only N2O, Aerosols, TSI, and MEI as features. What are the in-sample and out-of-sample R2, MSE, and MAE?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "afe02972",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In-sample R2 is:  0.6490120806760418\n",
      "In-sample MSE is:  0.009952007429105654\n",
      "In-sample MAE is:  0.07666650280233073\n",
      "Out-of-sample R2 is:  0.2003186110455797\n",
      "Out-of-sample MSE is:  0.006333308611893898\n",
      "Out-of-sample MAE is:  0.06154027269393324\n"
     ]
    }
   ],
   "source": [
    "# Creating a \"blank\" linear regression model\n",
    "LR_b = LinearRegression()\n",
    "\n",
    "# Using the \"fit\" function, which takes two arguments:\n",
    "# (1) A DataFrame consisting of the features (X),\n",
    "# and (2) a single column consisting of the dependent variable (y)\n",
    "features = ['N2O', 'Aerosols', 'TSI', 'MEI']\n",
    "X_train = df_train[features]\n",
    "y_train = df_train['Temp']\n",
    "LR_b.fit(X_train,y_train)\n",
    "\n",
    "X_test = df_test[features]\n",
    "y_test = df_test['Temp']\n",
    "\n",
    "# in-sample and out-of-sample R2 , MSE, and MAE\n",
    "y_train_pred = LR_b.predict(X_train) #for in-sample\n",
    "y_test_pred = LR_b.predict(X_test) #for out-of-sample\n",
    "\n",
    "print(\"In-sample R2 is: \", r2_score(y_train,y_train_pred))\n",
    "print(\"In-sample MSE is: \",mean_squared_error(y_train,y_train_pred))\n",
    "print(\"In-sample MAE is: \",mean_absolute_error(y_train,y_train_pred))\n",
    "\n",
    "print(\"Out-of-sample R2 is: \", r2_score(y_test,y_test_pred))\n",
    "print(\"Out-of-sample MSE is: \",mean_squared_error(y_test,y_test_pred))\n",
    "print(\"Out-of-sample MAE is: \",mean_absolute_error(y_test,y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f839dc62",
   "metadata": {},
   "source": [
    "(c) Between the two models built in parts (a) and (b), which performs better in-sample? Which performs better out-of-sample?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2455af1e",
   "metadata": {},
   "source": [
    "Answer: Between the two models, the model built in part (a) performs better in-sample, while the model built in part (b) performs better out-of-sample. This can be easily seen keeping in mind a higher R2 is better, and a lower MSE and MAE is better."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "903b2ce4",
   "metadata": {},
   "source": [
    "(d) For each of the two models built in parts (a) and (b), what was the regression coefficient for the N2O feature, and how should this coefficient be interpreted?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5495ba79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The regression coefficient for the N2O feature in part(a) was:  -0.034847807455777306\n",
      "A unit change in NO2 (i.e., an increase of 1 ppmv in NO2) leads to a change of -0.0348 in the difference (in degrees Celsius) between the average global temperature in that period and a reference value.\n"
     ]
    }
   ],
   "source": [
    "# for part (a)\n",
    "print(\"The regression coefficient for the N2O feature in part(a) was: \", LR_a.coef_[2])\n",
    "print(f\"A unit change in NO2 (i.e., an increase of 1 ppmv in NO2) leads to a change of {round(LR_a.coef_[2], 4)} in the difference (in degrees Celsius) between the average global temperature in that period and a reference value.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a5ed77db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The regression coefficient for the N2O feature in part(b) was:  0.024276120902004254\n",
      "A unit change in NO2 (i.e., an increase of 1 ppmv in NO2) leads to a change of 0.0243 in the difference (in degrees Celsius) between the average global temperature in that period and a reference value.\n"
     ]
    }
   ],
   "source": [
    "# for part (b)\n",
    "print(\"The regression coefficient for the N2O feature in part(b) was: \", LR_b.coef_[0])\n",
    "print(f\"A unit change in NO2 (i.e., an increase of 1 ppmv in NO2) leads to a change of {round(LR_b.coef_[0], 4)} in the difference (in degrees Celsius) between the average global temperature in that period and a reference value.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c3b6a4e",
   "metadata": {},
   "source": [
    "(e) Given your responses to parts (c) and (d), which of the two models should you prefer to use moving forward?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a108aa",
   "metadata": {},
   "source": [
    "Answer: Given our responses to parts (c) and (d), we should prefer the second model, i.e. the model built in part(b) moving forward. The current scientific opinion is that N2O is a greenhouse gas – a higher concentration traps more heat from the sun, and thus contributes to the heating of the Earth. This implies that an increase in NO2 concentration should increase the average global temperature, which means an increase in the 'Temp' variable. This means we should expect a positive regression coefficient for the N2O feature in the Linear Regression Model. We see this in the second model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
